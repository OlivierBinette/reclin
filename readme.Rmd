---
title: "reclin introduction"
author: "Jan van der Laan"
output: html_document
---

```{r}
library(devtools)
load_all()
```

We will work with a pair of data sets with artificial data. They are tiny, but 
that allows us to see what happens. 
```{r}
data("linkexample1", "linkexample2")
print(linkexample1)
print(linkexample2)
```

We have two data sets with personal information. The second data set contains a
lot of errors, but we will try to link the second data set to the first. 

In principle linkage consistst of comparing each combination of records from the
two data sets and determine which of those combinations (or pairs as we will
call them below) belong to the same entity. In case of a perfect linkage key, it
is of course, not necessary to compare all combinations of records, but when 
the linkage keys are imperfect and contain errors, it is in principle necessary 
to compare all pairs. 

However, comparing all pairs can result in an intractable number of 
pairs: when linking two data sets with a million records there are $10^{12}$ 
possible pairs. Therefore, some sort of reduction of the possible pairs is 
usually applied. In the example below, we apply *blocking*, which means that
pairs are only generated when they agree on the blocking variable (in this case
the postcode). This means that pairs of records that disagree on the blocking
variable are not considered. Therefore, one will only use variables that can
be considered without errors as blocking variable, or link multiple times with
different blocking variables and combine both data sets. 

The first step in (probabilistic) linkage is, therefore, generating all pairs:
```{r}
p <- pairs_blocking(linkexample1, linkexample2, "postcode")
print(p)
```

As you can see, record 1 from `x` (the first data set) is compared to records
1, 2 and 3 from `y`. 

We can now compare the records on their linkage keys:
```{r}
p <- pairs_compare(p, by = c("lastname", "firstname", "address", "sex"))
print(p)
```

The default comparison function returns `TRUE` when the linkage keys agree and
false when they don't. However, when looking at the original data sets, we can
see that most of our linkage keys are string variables that contain typing 
errors. The quality of our linkage could be improved if we could use a 
similarity score to compare the two strings: a high score means that the two 
strings are very similar a value close to zero means that the strings are very
different. 

Below we use the `jaro_winkler` similarity score to compare all fields:

```{r}
p <- pairs_compare(p, by = c("lastname", "firstname", "address", "sex"), 
  default_comparator = jaro_winkler(0.9))
print(p)
```

```{r}
m <- problink_em(p)

p <- score_simsum(p, var = "simsum")
p <- score_problink(p, model = m, var = "weight")

p <- select_n_to_m(p, "weight", var = "ntom_weight", threshold = 0)
p <- select_greedy(p, "weight", var = "greedy_weight", threshold = 0)

p <- select_n_to_m(p, "simsum", var = "ntom_simsum", threshold = 2)
p <- select_greedy(p, "simsum", var = "greedy_simsum", threshold = 2)

p <- add_from_x(p, id_x = "id") 
p <- add_from_y(p, id_y = "id")
p$true <- p$id_x == p$id_y

table(p$ntom_weight, p$true)
table(p$ntom_simsum, p$true)
table(p$greedy_simsum, p$true)
table(p$greedy_weight, p$true)

```

